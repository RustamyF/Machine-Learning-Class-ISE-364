{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The final project           \n",
    "## ISE 364                                                                          \n",
    "## Dr. Plebani \n",
    "## Team: \n",
    "## Mohanad Khazaali & Fahim Rustamy\n",
    "## Tuesday 12/18/2018\n",
    "****** Problem statement **********\n",
    "\n",
    "Find the best classification technique that predicts of whether a client will subscribe to a long-term deposit program or not. \n",
    "\n",
    "We have different supervised motheds (output known) that can be used:\n",
    "\n",
    "* a) The logistic regression\n",
    "* b) KNearestNeighbors (KNN)\n",
    "* c) Random forest\n",
    "* d) SVM\n",
    "* e) Neural Network using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the useful libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing                     # for numeric values finding \n",
    "from sklearn.linear_model import LogisticRegression   # use for logistic regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow\n",
    "import pickle                     # use with Keras\n",
    "%matplotlib inline\n",
    "sns.set_style(\"darkgrid\")        # the background of the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the given data:\n",
    "data = pd.read_csv(\"data.csv\")    # predict the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the data and their features \n",
    "* head\n",
    "* describe\n",
    "* info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* All the input variables are described in the description of the project\n",
    "* We need to know the output variable (desired target), has the client subscribed? (binary: \"yes\", \"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()    # we do not have any missing data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()  # we do not have any missing data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets take a look to the education catagories \n",
    "data['education'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['campaign'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will group ('basic.4y', 'basic.6y', 'basic.9y') together with one word 'basic' for a better modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace(['basic.4y', 'basic.6y', 'basic.9y'], 'basic', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets test it again\n",
    "data['education'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pdays'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration and visualizition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the data output feature \n",
    "sns.countplot(x='y',data=data, palette=\"seismic\") # it can be used any color from the colormap with palette=\"deep\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It can be seen from the above plot, we do have imbalance data classes**\n",
    "\n",
    "**Lets calculate the percentage of each one ('yes' or 'no')**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Client_no_sub=len(data[data['y']=='no'])\n",
    "Client_sub=len(data[data['y']=='yes'])\n",
    "Total=Client_no_sub+Client_sub\n",
    "percen_no_sub=Client_no_sub/Total*100\n",
    "percen_sub=Client_sub/Total*100\n",
    "print('The percentage of the client has NOT subscribed is:',percen_no_sub)\n",
    "print('The percentage of the client has subscribed is:',percen_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It obvious from the percentages that we need to balance our data!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the mean of the data according to y\n",
    "data.groupby('y').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **We need further visualization to get better understanding of our data**\n",
    "* **For example,the age result above is telling us that the average age of the client who bought the long term deposit is higher than the one who did not buy it! (still not give a good picture about the data)** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "**Lets take a look to the features to understand which feature is important compare to other** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# age feature\n",
    "g = sns.FacetGrid(data, col=\"y\")\n",
    "g = g.map(plt.hist, \"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['age'],kde=True, bins=30,color='g',hist_kws=dict(edgecolor='k', linewidth=.2, alpha=1)); \n",
    "plt.ylabel('Frequency')\n",
    "plt.title('age representation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Job feature (undestand number of participants in the subscription)\n",
    "sns.countplot(y='job', data=data, palette=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.crosstab(index, columns, values=None, rownames=None, colnames=None, aggfunc=None, margins=False, margins_name='All', dropna=True, normalize=False)\n",
    "pd.crosstab(data.job,data.y).plot(kind='bar')\n",
    "plt.title('Job representation')\n",
    "plt.xlabel('Job')\n",
    "plt.ylabel('Frequency of subscribed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marital feature (undestand number of participants in the subscription)\n",
    "sns.countplot(x='marital', data=data, palette=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.crosstab(index, columns, values=None, rownames=None, colnames=None, aggfunc=None, margins=False, margins_name='All', dropna=True, normalize=False)\n",
    "pd.crosstab(data.marital,data.y).plot(kind='bar')\n",
    "plt.title('Marital representation')\n",
    "plt.xlabel('Marital')\n",
    "plt.ylabel('Frequency of subscribed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Education feature (understand number of participants in the subscription)\n",
    "sns.countplot(y='education', data=data, palette=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.crosstab(index, columns, values=None, rownames=None, colnames=None, aggfunc=None, margins=False, margins_name='All', dropna=True, normalize=False)[source]\n",
    "pd.crosstab(data.education,data.y).plot(kind='bar')\n",
    "plt.title('Education representation')\n",
    "plt.xlabel('Education')\n",
    "plt.ylabel('Frequency of subscribed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# day_of_week feature (undestand number of participants in the subscription)\n",
    "sns.countplot(x='day_of_week', data=data, palette=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.crosstab(index, columns, values=None, rownames=None, colnames=None, aggfunc=None, margins=False, margins_name='All', dropna=True, normalize=False)[source]\n",
    "pd.crosstab(data.day_of_week,data.y).plot(kind='bar')\n",
    "plt.title('Days representation')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Frequency of subscribed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It can be seen that the day of the week is does not matter** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# campaign feature (undestand number of participants in the subscription)\n",
    "sns.countplot(x='campaign', data=data, palette=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data.campaign,data.y).plot(kind='bar')\n",
    "plt.title('campaign representation')\n",
    "plt.xlabel('campaign')\n",
    "plt.ylabel('Frequency of subscribed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# housing feature (undestand number of participants in the subscription)\n",
    "sns.countplot(x='housing', data=data, palette=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.crosstab(index, columns, values=None, rownames=None, colnames=None, aggfunc=None, margins=False, margins_name='All', dropna=True, normalize=False)[source]\n",
    "pd.crosstab(data.housing,data.y).plot(kind='bar')\n",
    "plt.title('housing representation')\n",
    "plt.xlabel('Housing')\n",
    "plt.ylabel('Frequency of subscribed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poutcome: outcome of the previous marketing campaign \n",
    "# Poutcome feature (undestand number of participants in the subscription)\n",
    "sns.countplot(x='poutcome', data=data, palette=\"deep\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.crosstab(index, columns, values=None, rownames=None, colnames=None, aggfunc=None, margins=False, margins_name='All', dropna=True, normalize=False)\n",
    "pd.crosstab(data.poutcome,data.y).plot(kind='bar')\n",
    "plt.title('Poutcome representation')\n",
    "plt.xlabel('Poutcome')\n",
    "plt.ylabel('Frequency of subscribed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loan feature (undestand number of participants in the subscription)\n",
    "sns.countplot(x='loan', data=data, palette=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.crosstab(index, columns, values=None, rownames=None, colnames=None, aggfunc=None, margins=False, margins_name='All', dropna=True, normalize=False)\n",
    "pd.crosstab(data.loan,data.y).plot(kind='bar')\n",
    "plt.title('loan representation')\n",
    "plt.xlabel('loan')\n",
    "plt.ylabel('Frequency of subscribed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contact feature (undestand number of participants in the subscription)\n",
    "sns.countplot(x='contact', data=data, palette=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pandas.crosstab(index, columns, values=None, rownames=None, colnames=None, aggfunc=None, margins=False, margins_name='All', dropna=True, normalize=False)\n",
    "pd.crosstab(data.contact,data.y).plot(kind='bar')\n",
    "plt.title('contact representation')\n",
    "plt.xlabel('contact')\n",
    "plt.ylabel('Frequency of subscribed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# contact feature (undestand number of participants in the subscription)\n",
    "sns.countplot(x='pdays', data=data, palette=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.crosstab(index, columns, values=None, rownames=None, colnames=None, aggfunc=None, margins=False, margins_name='All', dropna=True, normalize=False)\n",
    "pd.crosstab(data.pdays,data.y).plot(kind='bar')\n",
    "plt.title('pdays representation')\n",
    "plt.xlabel('pdays')\n",
    "plt.ylabel('Frequency of subscribed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default feature (undestand number of participants in the subscription)\n",
    "sns.countplot(x='default', data=data, palette=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.crosstab(index, columns, values=None, rownames=None, colnames=None, aggfunc=None, margins=False, margins_name='All', dropna=True, normalize=False)\n",
    "pd.crosstab(data.default,data.y).plot(kind='bar')\n",
    "plt.title('default representation')\n",
    "plt.xlabel('default')\n",
    "plt.ylabel('Frequency of subscribed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other features:\n",
    "***By looking at other features (i.e., day of week, and Pdays (most are 999)) will not affect our model significantly. So it can be neglected from the model (drop) (it can be included and see how will ghange the results)** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Summary of the Visualizations:\n",
    "\n",
    "* **1) The job feature has a great impact on our output (see the figure titled \"Job representation\")**\n",
    "* **2) The marital feature (i.e. married) has an impact on our output (see the figure titled \"Marital representation\"), but it is not significan**\n",
    "* **3) The Education feature seems to have an obvious impact on our output (see the figure titled \"Education representation\") **\n",
    "* **4) The day of the week feature seems to have a very weak impact on our output (see the figure titled \"days representation\") so it can be neglected**\n",
    "* **5) The cotact feature seems to have an acceptable impact on our output (see the figure titled \"contact representation\")**\n",
    "* **6) The housing, poutcome and loan features seem to have a good impact on our output, but with less weight compared to (1,2 and 3) (see the figures titled \"housing representation, poutcome representation, and loan representation\") **\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data,hue=\"y\", palette='deep', diag_kws=dict(edgecolor='gray',linewidth=.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *                                            **Visualization Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing the data\n",
    "* Lets eleminate the features that have less affect on the model (recall the visualization for which features are important)\n",
    "* we will drop 2 features (pdays and day_of_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['day_of_week','pdays'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To predict a good result we need to make our data smooth and uniform**\n",
    "* **Convert all the categorical features to numeric features (i.e the dummy variable (0,1) or the \n",
    "    most efficient technique \"LabelEncoder\")**\n",
    "* class sklearn.preprocessing.LabelEncoder\n",
    "* Encode labels with value between 0 and n_classes-1\n",
    "* https://scikit-learn.org/stable/modules/preprocessing_targets.html#preprocessing-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## call the LabelEncoder as le\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform all the features to numeric order!\n",
    "data.job = le.fit_transform(data.job)\n",
    "data.marital = le.fit_transform(data.marital)\n",
    "data.education = le.fit_transform(data.education)\n",
    "data.default = le.fit_transform(data.default)\n",
    "data.housing = le.fit_transform(data.housing)\n",
    "data.loan = le.fit_transform(data.loan)\n",
    "data.contact = le.fit_transform(data.contact)\n",
    "data.poutcome = le.fit_transform(data.poutcome)\n",
    "data.y = le.fit_transform(data.y)\n",
    "#data.y = le.inverse_transform(data.y)       # to go back to the categorical case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the new data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['job'].unique()   # we have 12 categorical job types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['marital'].unique()   # we have 4 categorical marital types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['education'].unique()   # we have 6 categorical education types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['default'].unique()   # we have 3 categorical default types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['housing'].unique()   # we have 3 categorical housing types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['loan'].unique()   # we have 3 categorical loan types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['contact'].unique()   # we have 2 categorical contact types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['poutcome'].unique()   # we have 3 categorical poutcome types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output\n",
    "data['y'].unique()   # we have 2 categorical output types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data,hue=\"y\", palette='deep', diag_kws=dict(edgecolor='gray',linewidth=.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix form for correlation data\n",
    "sns.heatmap(data.corr(),cmap='bwr',annot=False) #annot = true we get the number inside \n",
    "plt.title('data.corr()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eleminate the imbalance in the data\n",
    "**Imbalanced data typically refers to a problem with classification problems where the classes are not represented equally. As we we saw previously with the client responses:**\n",
    "* **Clients response with approximately 90% of \"no\"and 10% of \"yes\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets perfom the prediction with the logistic regression on our current data. It is expected to have a high accuracy since we have imblance data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_train=data.y\n",
    "X_train=data.drop('y', axis=1)\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)\n",
    "predictions = logmodel.predict(X_train)\n",
    "print(accuracy_score(predictions, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is it a good accuracy?**\n",
    "* Since we have imbalance data, its expected the majority of prediction to be only one class ('no')\n",
    "\n",
    "**There are several ways to balance the data (Resampling):**\n",
    "* Oversample the data (just increase the \"yes\" sample)\n",
    "* undersample the data (just decrease the \"no\" sample)\n",
    "* Changing your performance metric by using, The Receiver Operating Characteristic (ROC)\n",
    "* SMOTE (This object is an implementation of SMOTE - Synthetic Minority Over-sampling Technique), for more info:\n",
    "https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html\n",
    "* XG Boost\n",
    "* For more information about imbalance:\n",
    "* https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets\n",
    "\n",
    "* **Find the representation of the confusion matrix before oversampling:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_true=y_train, y_pred=predictions)\n",
    "print('Confusion matrix:\\n', conf_mat)\n",
    "\n",
    "labels = ['Class 0', 'Class 1']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(conf_mat, cmap=plt.cm.Reds)\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Expected')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling:\n",
    "* **Upsample minority class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "data_majority = data[data.y==0]\n",
    "data_minority = data[data.y==1]\n",
    " \n",
    "# Upsample minority class\n",
    "data_minority_upsampled = resample(data_minority, \n",
    "                                 replace=True,             # sample with replacement\n",
    "                                 n_samples=Client_no_sub,  # to match majority class\n",
    "                                 random_state=123)         # reproducible results\n",
    " \n",
    "# Combine results of the samples\n",
    "data_upsampled = pd.concat([data_majority, data_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "data_upsampled.y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find the data output feature \n",
    "sns.countplot(x='y',data=data_upsampled, palette=\"seismic\") # it can be used any color from the colormap with palette=\"deep\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the new data\n",
    "y_train=data_upsampled.y\n",
    "X_train=data_upsampled.drop('y', axis=1)\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)\n",
    "predictions = logmodel.predict(X_train)\n",
    "print(accuracy_score(predictions, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_true=y_train, y_pred=predictions)\n",
    "print('Confusion matrix:\\n', conf_mat)\n",
    "\n",
    "labels = ['Class 0', 'Class 1']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(conf_mat, cmap=plt.cm.Blues)\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Expected')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To have a higher diagonal values of the confusion matrix, the better indication can be acheived!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do undersampling by following the same procedure with oversampling, but lets perform SMOTE and see the behavior\n",
    "# SMOTE Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm=SMOTE(random_state=0)\n",
    "y=data.y\n",
    "X=data.drop('y', axis=1)\n",
    "data_train_x, data_test_x, data_train_y, data_test_y=train_test_split(X,y,test_size=0.30,random_state=0)\n",
    "columns=data_train_x.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can use SMOTE to balance our data\n",
    "sm_data_x,sm_data_y =sm.fit_sample(data_train_x,data_train_y)\n",
    "sm_data_x=pd.DataFrame(data=sm_data_x, columns=columns)\n",
    "sm_data_y=pd.DataFrame(data=sm_data_y, columns=['y'])\n",
    "\n",
    "# we can now check our data\n",
    "print('length of oversampled data is:',len(sm_data_x))\n",
    "print('Number of no subscribed client within new data is:',len(sm_data_y[sm_data_y['y']==0]))\n",
    "print('Number of subscribed client within new data is:',len(sm_data_y[sm_data_y['y']==1]))\n",
    "print(\"Percentage of no subscription within new data is \",len(sm_data_y[sm_data_y['y']==0])/len(sm_data_x))\n",
    "print(\"Percentage of subscription within new data is \",len(sm_data_y[sm_data_y['y']==1])/len(sm_data_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can see that we have balance classes!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(sm_data_x,sm_data_y)\n",
    "predictions = logmodel.predict(data_test_x)\n",
    "print(accuracy_score(predictions, data_test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_true=data_test_y, y_pred=predictions)\n",
    "print('Confusion matrix:\\n', conf_mat)\n",
    "\n",
    "labels = ['Class 0', 'Class 1']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(conf_mat, cmap=plt.cm.Reds)\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Expected')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the model\n",
    "* **Here we will use the data that we got from SMOTE (higher accuracy compare to oversampling) after oversampling to remove the imbalance**\n",
    "* **a) The logistic regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the previous libraries\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(sm_data_x,sm_data_y)        # these data after we did oversampling by SMOTE\n",
    "predictions = logmodel.predict(data_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_true=data_test_y, y_pred=predictions)\n",
    "print('Confusion matrix:\\n', conf_mat)\n",
    "\n",
    "labels = ['Class 0', 'Class 1']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(conf_mat, cmap=plt.cm.Reds)\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Expected')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print('classification_report is:')\n",
    "print(classification_report(data_test_y,predictions))\n",
    "print('confusion_matrix is:')\n",
    "print(confusion_matrix(data_test_y,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets try ROC and see if we can find any diffrence\n",
    "# Compare our results with the results that have published by Susan Li, sep,28,2017\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(data_test_y, logmodel.predict(data_test_x))\n",
    "fpr, tpr, thresholds = roc_curve(data_test_y, logmodel.predict_proba(data_test_x)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic, ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can conclude that the selected metrics evaluation can lead to different results (i.e, accuracy score, classification report, and ROC).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) KNearestNeighbors (KNN) classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_data_x[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(sm_data_x)\n",
    "scaled_x_train = scaler.fit_transform(sm_data_x)\n",
    "scaled_x_test = scaler.fit_transform(data_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x_train.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x_test.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x_train.var(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x_test.var(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)  # K=1\n",
    "## we do not need to split the data... it already splited when we used SMOTE\n",
    "knn.fit(scaled_x_train,sm_data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the predict method to predict values using your KNN model and X_test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = knn.predict(scaled_x_test)\n",
    "print('classification_report is:')\n",
    "print(classification_report(data_test_y,pred))\n",
    "print('confusion_matrix is:')\n",
    "print(confusion_matrix(data_test_y,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_true=data_test_y, y_pred=pred)\n",
    "print('Confusion matrix:\\n', conf_mat)\n",
    "\n",
    "labels = ['Class 0', 'Class 1']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(conf_mat, cmap=plt.cm.Reds)\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Expected')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a K Value\n",
    "Use the elbow method to pick a good K Value!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "error_rate = []\n",
    "\n",
    "for i in range(1,50):\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(scaled_x_train,sm_data_y)\n",
    "    pred_i = knn.predict(scaled_x_test)\n",
    "    error_rate.append(np.mean(pred_i != data_test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(range(1,50),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=5)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_roc_auc = roc_auc_score(data_test_y, pred)\n",
    "fpr, tpr, thresholds = roc_curve(data_test_y, knn.predict_proba(scaled_x_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='KNN (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic, ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Random forest classifier**\n",
    "* We know that the random forest classifier leads to best prediction compare to other Decision tree classifiers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfc.fit(sm_data_x, sm_data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions and Evaluation\n",
    "\n",
    "Let's predict off the y_test values and evaluate our model.\n",
    "\n",
    "** Predict the class of not.fully.paid for the X_test data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pred = rfc.predict(data_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_true=data_test_y, y_pred=rfc_pred)\n",
    "print('Confusion matrix:\\n', conf_mat)\n",
    "\n",
    "labels = ['Class 0', 'Class 1']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(conf_mat, cmap=plt.cm.Reds)\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Expected')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('classification_report is:')\n",
    "print(classification_report(data_test_y,rfc_pred))\n",
    "print('confusion_matrix is:')\n",
    "print(confusion_matrix(data_test_y,rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_roc_auc = roc_auc_score(data_test_y, rfc_pred)\n",
    "fpr, tpr, thresholds = roc_curve(data_test_y, rfc.predict_proba(data_test_x)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='RandomForest (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'g--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic, ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) SVM Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(sm_data_x, sm_data_y)      ##X_train,y_train= sm_data_x, sm_data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm = model.predict(data_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_true=data_test_y, y_pred=pred_svm)\n",
    "print('Confusion matrix:\\n', conf_mat)\n",
    "\n",
    "labels = ['Class 0', 'Class 1']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(conf_mat, cmap=plt.cm.Reds)\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Expected')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('classification_report is:')\n",
    "print(classification_report(data_test_y,pred_svm))\n",
    "print('confusion_matrix is:')\n",
    "print(confusion_matrix(data_test_y,pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_roc_auc = roc_auc_score(data_test_y, pred_svm)\n",
    "#fpr, tpr, thresholds = roc_curve(data_test_y, model.predict_proba(data_test_x)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='SVM (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'g--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic, ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e) Neural Network using Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(sm_data_x)\n",
    "scaled_x_train = scaler.fit_transform(sm_data_x)\n",
    "scaled_x_test = scaler.transform(data_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import models, layers\n",
    "from tensorflow.contrib.keras import activations, optimizers, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "* **If you run the data marke as Data.csv, use input_dim=13** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn = models.Sequential()\n",
    "dnn.add( layers.Dense(input_dim=13, units=10, activation='relu' ))  # grid search parameters  8 is power of 2 for gpu's\n",
    "dnn.add( layers.Dense(units=8, activation='relu' ))\n",
    "dnn.add( layers.Dense(units=8, activation='relu' ))\n",
    "dnn.add( layers.Dense(units=1, activation='sigmoid' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dnn.fit(scaled_x_train, sm_data_y, epochs=300, batch_size=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_keras = dnn.predict_classes(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(data_test_y==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_true=data_test_y, y_pred=pred_keras)\n",
    "print('Confusion matrix:\\n', conf_mat)\n",
    "\n",
    "labels = ['Class 0', 'Class 1']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(conf_mat, cmap=plt.cm.Reds)\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Expected')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "print('classification_report is:')\n",
    "print(classification_report(data_test_y,pred_keras))\n",
    "print('confusion_matrix is:')\n",
    "print(confusion_matrix(data_test_y,pred_keras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_roc_auc = roc_auc_score(data_test_y, pred_keras)\n",
    "#fpr, tpr, thresholds = roc_curve(data_test_y, dnn.predict_proba(scaled_x_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='NeuralNetwork (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'g--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic, ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets try with different activation function**\n",
    "* **If you run the data marke as Data.csv, use input_dim=13** \n",
    "* **If you run the data marke as futures.csv, use input_dim=13** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(10, input_dim=13, activation='tanh'))   # just one layer\n",
    "\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_keras = np.array(scaled_x_train)\n",
    "y_train_keras = np.array(sm_data_y)\n",
    "#print(x_train_keras.shape)\n",
    "y_train_keras = y_train_keras.reshape(y_train_keras.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(np.array(x_train_keras), np.array(y_train_keras), epochs=200, batch_size=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "pred_keras_n = model.predict_classes(scaled_x_test)\n",
    "print('classification_report is:')\n",
    "print(classification_report(data_test_y,pred_keras_n))\n",
    "print('confusion_matrix is:')\n",
    "print(confusion_matrix(data_test_y,pred_keras_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_roc_auc = roc_auc_score(data_test_y, pred_keras_n)\n",
    "#fpr, tpr, thresholds = roc_curve(data_test_y, model.predict_proba(scaled_x_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='NeuralNetwork (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'g--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic, ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Well, we can conclude that the rectified linear function with three layers gave us a good prediction compare to tan function**\n",
    "## Note that:\n",
    "**Based on the all 5 model classifiers that have been used, the Neural network using Keras has given the best prediction!**\n",
    "* ** The results have varified with some academic papers (i.e., Jiong Chen, Yucen Han, Zhao Hu, Yicheng Lu and Mengni Sun, Dec-7,2014)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## call the output\n",
    "**Here the data still oversampled**\n",
    "\n",
    "* **Create txt file, and save the output pred_keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_y=le.inverse_transform(pred_keras)  # convert the binary number to the char..\n",
    "output_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('futures_output_num.out', pred_keras, fmt='%0.1f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('futures_output.out','w') as f:\n",
    "    for s in output_y:\n",
    "        f.write(str(s)+'\\n')\n",
    "print(output_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_y=pd.DataFrame(output_y)\n",
    "print('The \"yes\" value is')\n",
    "print((output_y[0]=='yes').sum())\n",
    "print('The \"no\" value is')\n",
    "print((output_y[0]=='no').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(output_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the futures with Neural network by Keras\n",
    "\n",
    "* **Since we do not have confidence about our oversampling data(We do not know exactly which features dublicated to increse the number of samples. We used two type of data (feeding) in out predictions**\n",
    "\n",
    "\n",
    "* **1) The oversampled data (sm_data_x and sm_data_y) throgh SMOTE**\n",
    "* **2) Our original data  before resampling (Data.cvs) with (data_train_x and data_train_y)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_new=  pd.read_csv(\"futures.csv\")\n",
    "X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new.replace(['basic.4y', 'basic.6y', 'basic.9y'], 'basic', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "X_new.job = le.fit_transform(X_new.job)\n",
    "X_new.marital = le.fit_transform(X_new.marital)\n",
    "X_new.education = le.fit_transform(X_new.education)\n",
    "X_new.default = le.fit_transform(X_new.default)\n",
    "X_new.housing = le.fit_transform(X_new.housing)\n",
    "X_new.loan = le.fit_transform(X_new.loan)\n",
    "X_new.contact = le.fit_transform(X_new.contact)\n",
    "X_new.poutcome = le.fit_transform(X_new.poutcome)\n",
    "X_new.day_of_week = le.fit_transform(X_new.day_of_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new.drop(['day_of_week','pdays'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_new.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) The oversampled data (sm_data_x and sm_data_y) throgh SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn.fit(scaled_x_train, sm_data_y, epochs=300, batch_size=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(X_new)\n",
    "scaled_x_new = scaler.fit_transform(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_future=dnn.predict_classes(scaled_x_new)\n",
    "y_pred_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('y_pred_future_oversampled.out', y_pred_future, fmt='%0.1f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_future_req = list(y_pred_future)\n",
    "output_future_reqn = ['yes' if i == 1 else 'no' for i in output_future_req]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output_future_oversampled.out','w') as f:\n",
    "    for s in output_future_reqn:\n",
    "        f.write(str(s)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_future_reqn=pd.DataFrame(output_future_reqn)\n",
    "print('The \"yes\" value is')\n",
    "print((output_future_reqn[0]=='yes').sum())\n",
    "print('The \"no\" value is')\n",
    "print((output_future_reqn[0]=='no').sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Our original data  before resampling (Data.cvs) with (data_train_x and data_train_y)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(data_train_x)\n",
    "scaled_x_train = scaler.fit_transform(data_train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn.fit(scaled_x_train, data_train_y, epochs=300, batch_size=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_future=dnn.predict_classes(scaled_x_new)\n",
    "y_pred_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('y_pred_future_original.out', y_pred_future, fmt='%0.1f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_future_req_original = list(y_pred_future)\n",
    "output_future_req_originaln = ['yes' if i == 1 else 'no' for i in output_future_req_original]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output_future_original.out','w') as f:\n",
    "    for s in output_future_req_originaln:\n",
    "        f.write(str(s)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_future_req_originaln=pd.DataFrame(output_future_req_originaln)\n",
    "print('The \"yes\" value is')\n",
    "print((output_future_req_originaln[0]=='yes').sum())\n",
    "print('The \"no\" value is')\n",
    "print((output_future_req_originaln[0]=='no').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new['y']=output_future_req_originaln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new.to_csv('future_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
